{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPM2s8oKK/CmXpSV5QtYVl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hainesdata/gas/blob/main/lr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "import datetime\n",
        "import requests\n",
        "import regex as re\n",
        "import random\n",
        "import time\n",
        "import sys\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from statistics import stdev, mean, median, variance\n",
        "from math import sqrt\n",
        "from bs4 import BeautifulSoup\n",
        "from requests.exceptions import ProxyError"
      ],
      "metadata": {
        "id": "1VCyHf-3rm4G"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load raw gasbuddy dataset\n",
        "raw = pd.read_csv('gas_buddy_2022-04-18.csv')\n",
        "\n",
        "# Display variable properties\n",
        "raw.info()\n",
        "raw.nunique()"
      ],
      "metadata": {
        "id": "P2XjHgjBsXh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create working copy of raw data to preserve raw data\n",
        "sandbox = raw.copy()\n",
        "\n",
        "# Instantiate LabelEncoder and StandardScaler objects from scikit-learn\n",
        "le = LabelEncoder()\n",
        "s = StandardScaler()\n",
        "\n",
        "# Encode services feature, show distribution histogram (non ordinal)\n",
        "sandbox['services_included'] = le.fit_transform(sandbox['services_included'])\n",
        "px.histogram(x=sandbox['services_included'], height=300, width=500).show()\n",
        "\n",
        "# Filter prices listed as 0, show boxplot histogram of payment type\n",
        "sandbox = sandbox[sandbox['price_current'] != 0]\n",
        "px.box(sandbox, x='payment_type', y='price_current', width=400, height=500).show()\n",
        "\n",
        "# Show overall rating distribution\n",
        "px.histogram(x=sandbox['overall_rating'], height=300, width=500).show()\n",
        "\n",
        "# Show review count distribution\n",
        "px.histogram(x=sandbox['review_count'], height=300, width=500).show()\n",
        "\n",
        "# Encode station ID and show distribution\n",
        "le.fit(sandbox[['loc_number']])\n",
        "sandbox['loc_number'] = le.transform(sandbox[['loc_number']])\n",
        "px.histogram(x=sandbox['loc_number'], height=300, width=500).show()\n",
        "\n",
        "# Encode station name and show distribution\n",
        "le.fit(sandbox[['loc_name']])\n",
        "sandbox['loc_name'] = le.transform(sandbox[['loc_name']])\n",
        "px.histogram(x=sandbox['loc_name'], height=300, width=500).show()\n",
        "\n",
        "# Print number of unique cities\n",
        "print(len(sandbox['city'].unique()))\n",
        "\n",
        "# Encode city and show distribution\n",
        "le.fit(sandbox[['city']])\n",
        "sandbox['city'] = le.transform(sandbox[['city']])\n",
        "px.histogram(x=sandbox['city'], height=300, width=500).show()\n",
        "\n",
        "# Product name distribution\n",
        "px.box(sandbox, x='product_name', y='price_current', width=600).show()\n",
        "\n",
        "# Current price distribution\n",
        "px.histogram(sandbox, x='price_current', color='product_name', barmode='stack', nbins=64, width=1000).show()\n",
        "\n",
        "# Price vs review count relationship\n",
        "px.scatter(sandbox, x='review_count', y='price_current', trendline='ols', width=900).show()\n",
        "\n",
        "# Price vs rating relationship\n",
        "px.scatter(sandbox, x='overall_rating', y='price_current', trendline='ols', width=900).show()\n",
        "\n",
        "# Review vs rating count relationship\n",
        "px.scatter(sandbox, x='overall_rating', y='review_count', trendline='ols', width=900).show()\n",
        "\n",
        "# Price vs coordinate relationships \n",
        "px.scatter(sandbox, x='latitude', y='price_current', trendline='ols', width=900).show()\n",
        "px.scatter(sandbox, x='longitude', y='price_current', trendline='ols', width=900).show()\n",
        "\n",
        "# Station location map\n",
        "fig = px.scatter_mapbox(sandbox, lat=\"latitude\", lon=\"longitude\", \n",
        "                        hover_name='loc_name',\n",
        "                        hover_data=[\"latitude\",\"longitude\"],\n",
        "                        zoom=4, height=500, width=400\n",
        "                        )\n",
        "fig.update_layout(mapbox_style=\"open-street-map\")\n",
        "fig.show()\n",
        "\n",
        "# Location of stations with price less than USD $5, colored by product name\n",
        "fig = px.scatter_mapbox(sandbox[sandbox['price_current'] < 5], lat=\"latitude\", lon=\"longitude\", \n",
        "                        hover_name='loc_name',\n",
        "                        hover_data=[\"latitude\",\"longitude\"],\n",
        "                        zoom=4, height=500, width=400,\n",
        "                        color='product_name'\n",
        "                        )\n",
        "fig.update_layout(mapbox_style=\"open-street-map\")\n",
        "fig.show()\n",
        "\n",
        "# Location name vs price relationship\n",
        "px.scatter(sandbox, x='loc_name', y='price_current', width=900)"
      ],
      "metadata": {
        "id": "pehUJGiXsz1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset working dataset\n",
        "sandbox = raw.copy()\n",
        "\n",
        "# Drop features and exclude price zeros\n",
        "sandbox.drop(columns=['source_url', 'DATE_SCRAPED', 'RUN_START_DATE', \n",
        "                      'zip_code_searched', 'country', 'currency', 'state',\n",
        "                      'address_1', 'address_2', 'services_included', \n",
        "                      'price_time_stamp'\n",
        "                      ],\n",
        "             inplace=True)\n",
        "sandbox = sandbox[sandbox['price_current'] != 0]\n",
        "\n",
        "# Print number of unique values per feature and feature properties\n",
        "print(sandbox.nunique())\n",
        "print(sandbox.info())\n",
        "\n",
        "# Label-encode all features in input dataset that are strings\n",
        "def label_encode(df):\n",
        "    le = LabelEncoder()\n",
        "    for col in df.columns:\n",
        "        if type(df[col][0]) is str:\n",
        "            le = le.fit(df[[col]].values.ravel())\n",
        "            df[col] = le.transform(df[[col]].values.ravel())\n",
        "\n",
        "# (Unused, here for experimenting) One-hot encode string features given selected features passed to cols parameter\n",
        "def one_hot(df, cols):\n",
        "    ohe = OneHotEncoder()\n",
        "    for col in cols:\n",
        "        if type(df[col][0]) is str:\n",
        "            ohe = ohe.fit(df[[col]])\n",
        "            enc_arr = ohe.transform(df[[col]]).toarray()\n",
        "            onehot_df = pd.DataFrame(enc_arr, columns=ohe.get_feature_names_out([col]))\n",
        "            if len(onehot_df.columns) > 5000:\n",
        "                raise MemoryError(f'There are > 5000 columns in this encoded feature ({col}). Concatenating on input dataframe is expensive and may crash. Please reduce the number of columns for this feature or reduce the number of possible values for this feature.')\n",
        "            df = df.drop(columns=[col])\n",
        "            df = pd.concat([df, onehot_df], axis=1)\n",
        "    return df\n",
        "\n",
        "# Specify name of target variable and declare feature names as all columns excluding target name\n",
        "y_name = 'price_current'\n",
        "x_name = [name for name in sandbox.columns if name != y_name]\n",
        "\n",
        "# Encode dataset\n",
        "label_encode(sandbox)\n",
        "\n",
        "# Drop NAs and display metadata for encoded dataset\n",
        "sandbox = sandbox.dropna(how='any', axis=0)\n",
        "sandbox.info()\n",
        "\n",
        "# Train model\n",
        "def train_model(df):\n",
        "    # Specify name of target variable and declare feature names as all columns excluding target name\n",
        "    y_name = 'price_current'\n",
        "    x_name = [name for name in df.columns if name != y_name]\n",
        "    X = df[x_name]\n",
        "    y = df[y_name]\n",
        "\n",
        "    # Train-test split\n",
        "    X_t, X_v, y_t, y_v = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Instantiate linear regression and train model\n",
        "    lr = LinearRegression()\n",
        "    lr.fit(X_t, y_t)\n",
        "\n",
        "    # Print feature coefficients\n",
        "    weights = lr.coef_\n",
        "    print('WEIGHTS---------------------')\n",
        "    for i, w in zip(x_name, weights):\n",
        "        print(f'{i.ljust(20)} {w}')\n",
        "    print('')\n",
        "\n",
        "    # Validate model\n",
        "    y_hat = lr.predict(X_v)\n",
        "    err = y_v-y_hat\n",
        "    sigma_y = stdev(y_v)\n",
        "    sigma_e = stdev(err)\n",
        "    mse = mean_squared_error(y_v, y_hat)\n",
        "    lmbda = 1\n",
        "    me = sqrt(mse)\n",
        "    pe = me/(2*lmbda*sigma_y)\n",
        "    performance = me/(2*lmbda*sigma_e)\n",
        "\n",
        "    # Display model performance statistics\n",
        "    print('PERFORMANCE----------------')\n",
        "    print(f'{\"Mean Square Error\".ljust(20)} {mse}')\n",
        "    print(f'{\"Mean Error\".ljust(20)} {me}')\n",
        "    print(f'{\"Mean Percent Error\".ljust(20)} {pe}')\n",
        "    print(f'{\"Error Variance\".ljust(20)} {variance(err)}')\n",
        "    print(f'{\"Adj MSE Performance\".ljust(20)} {performance}')\n",
        "    px.histogram(x=err, width=900).show()\n",
        "\n",
        "    # Examine relationship between performance variable and standard deviation\n",
        "    x_p = []\n",
        "    y_p = []\n",
        "    for i in range(1, 5):\n",
        "        x_p.append(i)\n",
        "        y_p.append(me/(2*i*sigma_y))\n",
        "    x_e = []\n",
        "    y_e = []\n",
        "    for i in range(1, 5):\n",
        "        x_e.append(i)\n",
        "        y_e.append(me/(2*i*sigma_e))\n",
        "    fig = px.line(x=x_p, y=[y_p, y_e], labels={'x':'Lambda', 'value': 'Value'}, width=900)\n",
        "    newnames = {'wide_variable_0':'MPE', 'wide_variable_1': 'Adjusted MSE'}\n",
        "    fig.for_each_trace(lambda t: t.update(name = newnames[t.name],\n",
        "                                          legendgroup = newnames[t.name],\n",
        "                                          hovertemplate = t.hovertemplate.replace(t.name, newnames[t.name])\n",
        "                                        )\n",
        "                      )\n",
        "    fig.show()\n",
        "    return lr\n",
        "\n",
        "# Execute model training function\n",
        "model = train_model(sandbox)"
      ],
      "metadata": {
        "id": "gWJli-58vDzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get list of ten working proxies for webscraping\n",
        "def get_proxies():\n",
        "    # Get proxies from proxyscrape\n",
        "    url = 'https://gasbuddy.com'\n",
        "    proxies_url = 'https://api.proxyscrape.com/v2/?request=getproxies&protocol=http&timeout=10000&country=all&ssl=all&anonymity=all'\n",
        "    response = requests.get(proxies_url)\n",
        "    proxies = response.text.split('\\r\\n')\n",
        "\n",
        "    # Test proxies and return first one working\n",
        "    for proxy in proxies:\n",
        "        try:\n",
        "            r = requests.get(url, proxies={'http': proxy, 'https': proxy}, timeout=5)\n",
        "            check = u'\\u2713'\n",
        "            print(f'{check}\\t Proxy {proxy} is WORKING')\n",
        "            return proxy\n",
        "        except:\n",
        "            check = u'\\u2717'\n",
        "            print(f'{check}\\t Proxy {proxy} is not working')\n",
        "    raise ProxyError('Proxy list exhausted, no working proxies found.')\n",
        "    \n",
        "# Load a given page using proxy\n",
        "def load_page(url, proxy='none'):\n",
        "    # Define header\n",
        "    hdr = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36',\n",
        "    'Accept-Language': 'en-US,en;q=0.5'\n",
        "    }    \n",
        "\n",
        "    # If 'none' is passed into the proxy parameter, perform request without proxy. Otherwise, the proxy address passed is used\n",
        "    if proxy == 'none':\n",
        "        resp = requests.get(url, headers=hdr)\n",
        "        return resp\n",
        "    resp = requests.get(url, headers=hdr, proxies={'http':f'{proxy}', 'https':f'{proxy}'})\n",
        "    return resp\n",
        "\n",
        "# Get station IDs for zipcode passed into zipcode parameter\n",
        "def get_ids(zipcode, proxy, debug=True):\n",
        "    # Get Gasbuddy search results\n",
        "    url = f\"https://www.gasbuddy.com/home?search={zipcode}&fuel=1&method=all&maxAge=24\"\n",
        "    resp = load_page(url, proxy)\n",
        "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "\n",
        "    # Prints response for debug\n",
        "    if debug:\n",
        "        print(resp)\n",
        "    \n",
        "    # Get IDs from search results\n",
        "    u = []\n",
        "    ids = soup.select('div[class*=\"GenericStationListItem-module__station___\"]')\n",
        "    for i in ids:\n",
        "        u.append(i.get('id'))\n",
        "    return u\n",
        "\n",
        "# Parse gas station info\n",
        "def get_info(id, city, proxy):\n",
        "    # Load gas station page\n",
        "    url = f\"https://www.gasbuddy.com/station/{id}\"\n",
        "    resp = load_page(url, proxy)\n",
        "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "\n",
        "    # Parse zipcode\n",
        "    features = []\n",
        "    zip_match = re.search(r'CA,([0-9]{5})', str(soup.select('a[class*=\"Station-module__directionsLink___\"]')[0].get('href')))\n",
        "    postal_code = zip_match.group(1) if zip_match else None\n",
        "    features.append(postal_code)\n",
        "\n",
        "    # Parse location name\n",
        "    try:\n",
        "        loc_name = [item.text.split(\"\\xa0\")[0] for item in soup.select('h2[class*=\"StationInfoBox-module__header___\"]')][0]\n",
        "    except IndexError:\n",
        "        try:\n",
        "            loc_name = [item.text for item in soup.select('h2[class*=\"StationInfoBox-module__header___\"]')]\n",
        "        except IndexError:\n",
        "            print('Error parsing loc_name: no stations exist in the zipcode or zipcode does not exist. Skipping...')\n",
        "            return 0\n",
        "    features.append(loc_name)\n",
        "\n",
        "    # Get city from city parameter and add to features\n",
        "    features.append(city)\n",
        "\n",
        "    # Parse number of reviews on station\n",
        "    review_count = int([re.split(\"[()]+\", item.text)[1] for item in soup.select('span[class*=\"StationInfoBox-module__ratings___\"]')][0])\n",
        "    features.append(review_count)\n",
        "\n",
        "    # Parse station latitude\n",
        "    try:\n",
        "        latitude = float(str(soup.select('a[class*=\"Station-module__directionsLink___\"]')[0].get('href')).split('@')[1].split(',')[0])\n",
        "    except:\n",
        "        print(f'Error parsing latitude. Skipping...')\n",
        "        return 0\n",
        "    features.append(latitude)\n",
        "\n",
        "    # Add station ID to features\n",
        "    features.append(id)\n",
        "\n",
        "    # Parse station phone number\n",
        "    try:\n",
        "        phone = [item.text for item in soup.select('a[class*=\"PhoneLink-module__blue___\"]')][0]\n",
        "    except IndexError:\n",
        "        phone = ''\n",
        "        print(f'Error parsing phone: Either phone was empty or incorrect. Skipping...')\n",
        "    features.append(phone)\n",
        "\n",
        "    # Parse station longitude\n",
        "    try:\n",
        "        longitude = float(str(soup.select('a[class*=\"Station-module__directionsLink___\"]')[0].get('href')).split('@')[1].split(',')[1])\n",
        "    except:\n",
        "        print(f'Error parsing longitude. Skipping...')\n",
        "        return 0\n",
        "    features.append(longitude)\n",
        "\n",
        "    # Gasbuddy shows credit price by default, so add credit to features as payment type\n",
        "    payment_method = 'Credit'\n",
        "    features.append(payment_method)\n",
        "\n",
        "    # Parse station rating\n",
        "    try:\n",
        "        overall_rating = float([item.text for item in soup.select('span[class*=\"Station-module__ratingAverage___\"]')][0])\n",
        "    except ValueError:\n",
        "        return 0\n",
        "    features.append(overall_rating)\n",
        "\n",
        "    # Create dictionary for gas type and respective price\n",
        "    price_val = [item.text for item in soup.select('span[class*=\"FuelTypePriceDisplay-module__price___\"]')]\n",
        "    price_key = [item.text for item in soup.select('span[class*=\"GasPriceCollection-module__fuelTypeDisplay\"]')]\n",
        "    prices = {k:v for k,v in zip(price_key, price_val)}\n",
        "    features.append(prices)\n",
        "\n",
        "    return features\n",
        "\n",
        "# Create test dataframe\n",
        "df_test = pd.DataFrame(columns=['postal_code', 'loc_name', 'city', 'review_count', 'latitude', 'loc_number', 'phone', 'longitude', 'payment_type', 'overall_rating', 'prices'])\n",
        "\n",
        "# Load California zipcodes and cities\n",
        "zipcodes = pd.read_csv('zipcodes.us.csv', usecols=['state_code', 'zipcode', 'place'])\n",
        "zipcodes = zipcodes[zipcodes['state_code'] == 'CA'].drop(columns=['state_code'])\n",
        "\n",
        "# Specify number of zipcodes to search in\n",
        "n = 25\n",
        "\n",
        "# Scrape\n",
        "for k, i in enumerate(zipcodes['zipcode'].sample(n+1)):\n",
        "    print(f'({k}/{n})')\n",
        "    print(f'[Zip: {i}] Retrieving IDs...')\n",
        "    ids = get_ids(i)\n",
        "    print(f'[Zip: {i}] Done.')\n",
        "    failed = False\n",
        "    for j in ids:\n",
        "        print(f'[Zip: {i}] Retrieving ID {j} features...')\n",
        "        features = get_info(j, zipcodes.iloc[k]['place'])\n",
        "        if features == 0:\n",
        "            failed = True\n",
        "            break\n",
        "        df_test.loc[len(df_test)] = features\n",
        "        print(f'[Zip: {i}] Done.')\n",
        "    if failed:\n",
        "        print(f'[Zip: {i}] Parse failed.')\n",
        "        continue\n",
        "    print(f'[Zip: {i}] Parse successful.')\n",
        "    cooldown = 5\n",
        "    for t in range(cooldown, 0, -1):\n",
        "        print(f\"\\rCooldown: {t}s\", end='')\n",
        "        time.sleep(1)\n",
        "    print(f\"\\rCooldown: Done.\", end='')\n",
        "    print('\\n')\n",
        "\n",
        "# Export scraped data to CSV\n",
        "df_test.to_csv('gasbuddy_test.csv', index=False)\n",
        "print('Test data retrieved successfully and saved to gasbuddy_test.csv')"
      ],
      "metadata": {
        "id": "4aA-Pev4AACi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load local test dataframe. If it doesn't exist in environment, load last exported CSV.\n",
        "try:\n",
        "    df_test_2 = df_test.copy()\n",
        "except:\n",
        "    df_test_2 = pd.read_csv('gasbuddy_test.csv')\n",
        "\n",
        "# Unpack product prices\n",
        "product_prices = pd.DataFrame(df_test_2['prices'].tolist()).stack().reset_index(level=1).rename(columns={0:'price_current'})\n",
        "product_prices['product_name'] = product_prices['level_1']\n",
        "product_prices = product_prices.drop('level_1', axis=1)\n",
        "df_test_2 = pd.merge(df_test_2, product_prices, left_on=df_test_2.index, how='left', right_on=product_prices.index)\n",
        "df_test_2 = df_test_2.drop(columns=['prices', 'key_0'])\n",
        "df_test_2 = df_test_2[df_test_2['price_current'] != '- - -']\n",
        "df_test_2['price_current'] = [float(i.replace('$','')) for i in df_test_2['price_current']]\n",
        "df_test_2 = df_test_2.reset_index(drop=True)\n",
        "df_test_2[:5]\n",
        "\n",
        "# Preprocess validation data\n",
        "y_name = 'price_current'\n",
        "x_name = [name for name in sandbox.columns if name != y_name]\n",
        "label_encode(df_test_2)\n",
        "df_test_2 = df_test_2.dropna(how='any', axis=0)\n",
        "print(df_test_2.info())\n"
      ],
      "metadata": {
        "id": "B7dQbRqZV_O7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run predictions and output error distribution\n",
        "test_results = pd.DataFrame()\n",
        "test_results['y_hat_test'] = model.predict(df_test_2[x_name])\n",
        "test_results['y_test'] = df_test_2['price_current']\n",
        "test_results['diff'] = test_results['y_test'] - test_results['y_hat_test']\n",
        "px.histogram(test_results, x='diff', nbins=100, width=900, marginal='violin')"
      ],
      "metadata": {
        "id": "Zy2ZS4xJiGTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L0k5WMKEm_FV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}