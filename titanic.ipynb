{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hainesdata/gas/blob/main/titanic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruHHzX-Fmm9F"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def format_raw(df):\n",
        "  # df.drop(columns=['Ticket', 'Embarked', 'Cabin', 'SibSp', 'Age'], inplace=True)\n",
        "  df['Cabin'] = [(x[0] if type(x) is str else 'X') for x in df['Cabin']]\n",
        "  return df\n",
        "\n",
        "_df_train = format_raw(pd.read_csv('train.csv'))\n",
        "_df_test = format_raw(pd.read_csv('test.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore\n",
        "\n",
        "# Should drop Cabin and Age, but don't know how much of an affect this has on the training yet\n",
        "_df_train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUjlrry_8hHN",
        "outputId": "eb4991e5-2163-47df-e7cf-6f0330ff3341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        891 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check survival rates\n",
        "print(_df_train['Survived'].value_counts())\n",
        "print(_df_train['Survived'].value_counts(normalize=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVtyGY8c9Jo0",
        "outputId": "d25ee70f-5946-4ace-fea9-b97fa802369b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    549\n",
            "1    342\n",
            "Name: Survived, dtype: int64\n",
            "0    0.616162\n",
            "1    0.383838\n",
            "Name: Survived, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Since rates are imbalanced, needs to have equal proportion of survived and not survived\n",
        "# Will undersample\n",
        "\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "train = _df_train.copy()\n",
        "y = 'Survived'\n",
        "x_names = [c for c in train.columns if c != y]\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "train_x, train_y = rus.fit_resample(train[x_names], train[y])\n",
        "train = pd.concat([train_x, train_y], axis=1)\n",
        "train[y].value_counts(normalize=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz1FosTu9_bN",
        "outputId": "6b53b020-bfaa-477c-c373-d7aa613b6b17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.5\n",
              "1    0.5\n",
              "Name: Survived, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sex-Survival relationship\n",
        "_df_train.groupby('Sex')[y].mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VukXThj38Xs",
        "outputId": "67b5ae61-1d34-4fe2-ca25-316a0680c481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sex\n",
              "female    0.742038\n",
              "male      0.188908\n",
              "Name: Survived, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Class-Survival relationship\n",
        "_df_train.groupby('Pclass')[y].mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lN6AKYS-4szS",
        "outputId": "22cfb81b-b256-4b0a-b5ad-37a0ae850e80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pclass\n",
              "1    0.629630\n",
              "2    0.472826\n",
              "3    0.242363\n",
              "Name: Survived, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "from math import sqrt\n",
        "\n",
        "# LogiRegr\n",
        "def preprocess_lr(_df, x, y, i, tt, test=False, make_bins=False, standardize=False):\n",
        "    df = _df.copy()\n",
        "    le = LabelEncoder()\n",
        "    if test:\n",
        "        cols = [c for c in x if c not in y]\n",
        "    else:\n",
        "        cols = [c for c in x if c not in y and c not in i] \n",
        "    for i in cols:\n",
        "        if isinstance(df[i][1], str):\n",
        "            df[i] = le.fit_transform(df[i])\n",
        "        if isinstance(df[i][1], float):\n",
        "            X_bar = np.mean(df[i])\n",
        "            df[i] = df[i].fillna(X_bar)\n",
        "        if make_bins:\n",
        "            df[f'{i}_bin'] = le.fit_transform(pd.cut(df[i], int(sqrt(len(df[i]))), duplicates='drop'))\n",
        "    if standardize:\n",
        "        df = scale(df, cols)\n",
        "    if test:\n",
        "        return df\n",
        "    else:\n",
        "        xt, xv, yt, yv = train_test_split(df[cols], df[y], test_size=tt, random_state=42)\n",
        "        return xt, xv, yt, yv\n",
        "\n",
        "def scale(df, x):\n",
        "    s = StandardScaler()\n",
        "    s.fit(df[x])\n",
        "    df[x] = s.transform(df[x])\n",
        "    return df\n",
        "\n",
        "def instantiate_lr(df, x, y, i, tt, bins, std=False):\n",
        "    xt, xv, yt, yv = preprocess_lr(df, x, y, i, tt, standardize=std, make_bins=bins)\n",
        "    model = LogisticRegression(max_iter=1000)\n",
        "    model.fit(xt, yt)\n",
        "    y_hat = model.predict(xv)\n",
        "    acc = accuracy_score(yv, y_hat)\n",
        "    print(f'Accuracy: {acc}')\n",
        "    return model\n",
        "\n",
        "def run_lr(train, test, y, i, tt, std, bins):\n",
        "    x = [c for c in train.columns if c not in i and c not in y]\n",
        "    model = instantiate_lr(train, x, y, i, tt=tt, std=std, bins=bins)\n",
        "    y_hat = pd.DataFrame()\n",
        "    _test = preprocess_lr(test, x, y, i, tt, standardize=std, test=True, make_bins=bins)\n",
        "    y_hat[y] = model.predict(_test[x])\n",
        "    y_hat[i] = test[i]\n",
        "    return y_hat\n",
        "\n",
        "# SVM\n",
        "def preprocess_svm(_df, x, y, i, tt, test=False, make_bins=False, standardize=False):\n",
        "    df = _df.copy()\n",
        "    le = LabelEncoder()\n",
        "    if test:\n",
        "        cols = [c for c in x if c not in y]\n",
        "    else:\n",
        "        cols = [c for c in x if c not in y and c not in i] \n",
        "    for i in cols:\n",
        "        if isinstance(df[i][1], str):\n",
        "            df[i] = le.fit_transform(df[i])\n",
        "        if isinstance(df[i][1], float):\n",
        "            X_bar = np.mean(df[i])\n",
        "            df[i] = df[i].fillna(X_bar)\n",
        "        if make_bins:\n",
        "            df[f'{i}_bin'] = le.fit_transform(pd.cut(df[i], int(sqrt(len(df[i]))), duplicates='drop'))\n",
        "    if standardize:\n",
        "        df = scale(df, cols)\n",
        "    if test:\n",
        "        return df\n",
        "    else:\n",
        "        xt, xv, yt, yv = train_test_split(df[cols], df[y], test_size=tt, random_state=42)\n",
        "        return xt, xv, yt, yv\n",
        "\n",
        "def instantiate_svm(df, x, y, i, tt, bins, std=False, kind='c', kernel='linear'):\n",
        "    xt, xv, yt, yv = preprocess_svm(df, x, y, i, tt, standardize=std, make_bins=bins)\n",
        "    if kind == 'linear':\n",
        "        model = svm.LinearSVC(penalty='l2', loss='squared_hinge', dual=False)\n",
        "    elif kind == 'c':\n",
        "        model = svm.SVC(kernel=kernel)\n",
        "    elif kind == 'nu':\n",
        "        model = svm.NuSVC(kernel=kernel)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid SVM algorithm specified. Expected one of the following: 'linear', 'c', 'nu'. Using SVC with default parameters.\")\n",
        "    model.fit(xt, yt)\n",
        "    y_hat = model.predict(xv)\n",
        "    acc = accuracy_score(yv, y_hat)\n",
        "    print(f'Accuracy: {acc}')\n",
        "    return model\n",
        "\n",
        "def run_svm(train, test, y, i, tt, std, bins, kind='c', kernel='linear'):\n",
        "    x = [c for c in train.columns if c not in i and c not in y]\n",
        "    model = instantiate_svm(train, x, y, i, tt, std=std, bins=bins, kind=kind, kernel=kernel)\n",
        "    y_hat = pd.DataFrame()\n",
        "    _test = preprocess_svm(test, x, y, i, tt, standardize=std, test=True, make_bins=bins)\n",
        "    y_hat[y] = model.predict(_test[x])\n",
        "    y_hat[i] = test[i]\n",
        "    return y_hat\n",
        "\n",
        "# RF approach\n",
        "def preprocess_rf(df, x, y, i, tt, test=False, make_bins=False, standardize=False):\n",
        "    le = LabelEncoder()\n",
        "    if test:\n",
        "        cols = [c for c in x if c not in y]\n",
        "    else:\n",
        "        cols = [c for c in x if c not in y and c not in i] \n",
        "    for i in cols:\n",
        "        if isinstance(df[i][1], str):\n",
        "            df[i] = le.fit_transform(df[i])\n",
        "        if isinstance(df[i][1], float):\n",
        "            X_bar = np.mean(df[i])\n",
        "            df[i] = df[i].fillna(X_bar)\n",
        "        if make_bins:\n",
        "            df[f'{i}_bin'] = le.fit_transform(pd.cut(df[i], int(sqrt(len(df[i]))), duplicates='drop'))\n",
        "    if standardize:\n",
        "        df = scale(df, cols)\n",
        "    if test:\n",
        "        return df\n",
        "    else:\n",
        "        xt, xv, yt, yv = train_test_split(df[cols], df[y], test_size=tt, random_state=42)\n",
        "        return xt, xv, yt, yv\n",
        "\n",
        "def instantiate_rf(df, x, y, i, tt, trees, depth, split, std, bins):\n",
        "    xt, xv, yt, yv = preprocess_rf(df, x, y, i, tt, standardize=std, make_bins=bins)\n",
        "    model = RandomForestClassifier(n_estimators=trees, max_depth=depth, max_features='sqrt', min_samples_split=split)\n",
        "    model.fit(xt, yt)\n",
        "    y_hat = model.predict(xv)\n",
        "    acc = accuracy_score(yv, y_hat)\n",
        "    print(f'Accuracy: {acc}')\n",
        "    return model\n",
        "\n",
        "def run_rf(train, test, y, i, tt, trees, depth, split, std=False, bins=False):\n",
        "    x = [c for c in train.columns if c not in i and c not in y]\n",
        "    model = instantiate_rf(train, x, y, i, tt, trees, depth, split, std=std, bins=bins)\n",
        "    y_hat = pd.DataFrame()\n",
        "    _test = preprocess_rf(test, x, y, i, tt, standardize=std, test=True, make_bins=bins)\n",
        "    y_hat[y] = model.predict(_test[x])\n",
        "    y_hat[i] = test[i]\n",
        "    return y_hat\n",
        "\n",
        "train = _df_train.copy()\n",
        "test = _df_test.copy()\n",
        "\n",
        "y = 'Survived'\n",
        "i = 'PassengerId'\n",
        "\n",
        "pred_rf = run_rf(train, test, y, i, tt=0.05, std=True, bins=False, trees=100, depth=15,split=2)\n",
        "pred_rf.to_csv('result_rf.csv', index=False)\n",
        "\n",
        "pred_svm = run_svm(train, test, y, i, tt=0.05, std=False, bins=False, kind='linear', kernel='rbf')\n",
        "pred_svm.to_csv('result_svm.csv', index=False)\n",
        "\n",
        "pred_lr = run_lr(train, test, y, i, tt=0.05, std=False, bins=False)\n",
        "pred_lr.to_csv('result_lr.csv', index=False)\n",
        "\n",
        "preds = pd.merge(pred_rf, pred_lr, on=i)\n",
        "preds = pd.merge(preds, pred_svm, on=i)\n",
        "preds.set_index(i, inplace=True)\n",
        "preds[y] = preds.mean(axis=1)\n",
        "preds = preds[y]\n",
        "preds = preds.reset_index()\n",
        "preds[y] = preds[y].apply(lambda y_i: 0 if y_i < 0.5 else 1)\n",
        "preds.to_csv('result_ensemble.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8MGq7zNEZRK",
        "outputId": "ab958f78-ce58-41ad-d245-3951810a7e45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7555555555555555\n",
            "Accuracy: 0.8222222222222222\n",
            "Accuracy: 0.8222222222222222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWzQzdjFm-oM"
      },
      "outputs": [],
      "source": [
        "44# DNN approach\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, BatchNormalization, LeakyReLU\n",
        "from keras.callbacks import TensorBoard\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import SGD\n",
        "from keras.initializers import glorot_normal, Zeros\n",
        "from keras import regularizers\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_history(history):\n",
        "    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
        "    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
        "    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
        "    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
        "    \n",
        "    if len(loss_list) == 0:\n",
        "        print('Loss is missing in history')\n",
        "        return \n",
        "    \n",
        "    ## As loss always exists\n",
        "    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
        "    \n",
        "    ## Loss\n",
        "    plt.figure(1)\n",
        "    for l in loss_list:\n",
        "        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
        "    for l in val_loss_list:\n",
        "        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
        "    \n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    \n",
        "    ## Accuracy\n",
        "    plt.figure(2)\n",
        "    for l in acc_list:\n",
        "        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
        "    for l in val_acc_list:    \n",
        "        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
        "\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def scale(df, numerics):\n",
        "    s = StandardScaler()\n",
        "    s.fit(df[numerics])\n",
        "    df[numerics] = s.transform(df[numerics])\n",
        "    return df\n",
        "\n",
        "def preprocess(_df, x, y, N, y_cat, mode='one-hot'):\n",
        "    df = _df.copy().dropna()\n",
        "    ohe = OneHotEncoder()\n",
        "    le = LabelEncoder()\n",
        "    categories = [u for u in x if u not in N]\n",
        "    for i in categories:\n",
        "        if type(df[i][1]) is str:\n",
        "            df[i] = le.fit_transform(df[i])\n",
        "            df[i] = to_categorical(df[i], len(df[i].unique()))\n",
        "        else:\n",
        "            df[i] = to_categorical(df[i], len(df[i].unique()))\n",
        "    if y_cat:\n",
        "          df[y] = to_categorical(df[y], len(df[y].unique()))\n",
        "    x_t, x_v, y_t, y_v = train_test_split(\n",
        "        df[x], df[y], test_size=0.1, random_state=42)\n",
        "    x_t = scale(x_t, N)\n",
        "    x_v = scale(x_v, N)\n",
        "    return x_t, x_v, y_t, y_v\n",
        "\n",
        "def preprocess_test(_df, x, N):\n",
        "    df = _df[x]\n",
        "    le = LabelEncoder()\n",
        "    for i in x:\n",
        "        if type(df[i][1]) is str:\n",
        "            df[i] = le.fit_transform(df[i])\n",
        "            df[i] = to_categorical(df[i], len(df[i].unique()))\n",
        "        if type(df[i][1] is float):\n",
        "            X_bar = np.mean(df[i])\n",
        "            df[i] = df[i].fillna(X_bar)\n",
        "    df = scale(df, N)\n",
        "    df = np.array(df).astype('float32')\n",
        "    return df\n",
        "\n",
        "def make_model(df, params, outs, numerics, y_is_categorical=True, epochs=128, batch=32, auto_epoch=False):\n",
        "    x_train, x_valid, y_train, y_valid = preprocess(df, params, outs, numerics, y_is_categorical)\n",
        "    if auto_epoch:\n",
        "      epochs = len(df)//batch\n",
        "    model = Sequential()\n",
        "    model.add(Dense(8, activation='relu', input_shape=(len(params),), kernel_initializer=glorot_normal, bias_initializer=Zeros))\n",
        "    model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(1e-5)))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer=SGD(learning_rate=0.001), metrics=['accuracy'])\n",
        "    \n",
        "    history = model.fit(x_train, y_train, batch_size=batch, epochs=epochs, verbose='auto', validation_data=(x_valid, y_valid))\n",
        "    return model, history\n",
        "\n",
        "nums = ['Age', 'Pclass', 'SibSp']\n",
        "x = ['Age', 'Pclass', 'SibSp', 'Sex', 'Cabin']\n",
        "y = 'Survived'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model, history = make_model(df_train, params=x, outs=y, numerics=nums, batch=32, epochs=300)\n",
        "plot_history(history)"
      ],
      "metadata": {
        "id": "G_NGqXRE8Le7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = preprocess_test(df_test, x, nums)\n",
        "y_hat = model.predict(X).tolist()\n",
        "result = pd.DataFrame()\n",
        "result['PassengerId'] = df_test['PassengerId']\n",
        "result['Survived'] = [1 if x > 0.5 else 0 for [x] in y_hat]"
      ],
      "metadata": {
        "id": "hi8UtGvyezcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.to_csv('results.csv', index=False)"
      ],
      "metadata": {
        "id": "4w8kK_0_DDvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J4xFyN1M3mMl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1XYN4xmffnZU6at3eXD0H",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}